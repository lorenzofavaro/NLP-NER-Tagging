{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8dd84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from conllu import parse_incr, TokenList\n",
    "from enum import Enum\n",
    "from typing import Iterator, List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb17e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothingStrategy(Enum):\n",
    "    uniform = 1\n",
    "    always_other = 2\n",
    "    other_and_misc = 3\n",
    "    one_shot_word = 4\n",
    "\n",
    "smoothing_strategy = None\n",
    "laplace_correction = np.finfo(float).tiny\n",
    "lang = 'eng'\n",
    "train_set = open(f\"data/{lang}/train.conllu\", \"r\", encoding=\"utf-8\")\n",
    "test_set = open(f\"data/{lang}/test.conllu\", \"r\", encoding=\"utf-8\")\n",
    "val_set = open(f\"data/{lang}/val.conllu\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "tags = ['START', 'O', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'B-LOC', 'B-MISC', 'B-PER', 'B-ORG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7b393",
   "metadata": {},
   "source": [
    "## Smoothing strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbe5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_word_emission(smoothing_strategy: Enum, tag: str) -> float:\n",
    "    if smoothing_strategy == SmoothingStrategy.uniform:\n",
    "        return 1 / len(tags)\n",
    "    elif smoothing_strategy == SmoothingStrategy.always_other:\n",
    "        if tag == 'O':\n",
    "            return 1\n",
    "    elif smoothing_strategy == SmoothingStrategy.other_and_misc:\n",
    "        if tag == 'O' or tag == 'B-MISC':\n",
    "            return 0.5\n",
    "    elif smoothing_strategy == SmoothingStrategy.one_shot_word:\n",
    "        return one_shot_distrib[tag]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bf04d",
   "metadata": {},
   "source": [
    "## Matrix Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7704b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_matrix(tags: List[str], train_set: Iterator[TokenList]) -> np.array:\n",
    "    transition_matrix = np.zeros((len(tags), len(tags)), dtype=float)\n",
    "\n",
    "    tag_counter = defaultdict(int)\n",
    "    transition_counter = defaultdict(int)\n",
    "\n",
    "    for sentence in parse_incr(train_set):\n",
    "        # count first tag of sentence and match it with 'START' artificial tag\n",
    "        first_tag = sentence[0]['lemma']\n",
    "        tag_counter['START'] += 1\n",
    "        transition_counter[('START', first_tag)] += 1\n",
    "\n",
    "        # count middle token pairs\n",
    "        for (token_a, token_b) in zip(sentence, sentence[1:]):\n",
    "            tag_counter[token_a['lemma']] += 1\n",
    "            transition_counter[(token_a['lemma'], token_b['lemma'])] += 1\n",
    "\n",
    "        # count last tag of sentence\n",
    "        tag_counter[sentence[-1]['lemma']] += 1\n",
    "\n",
    "    for i, t1 in enumerate(tags):\n",
    "        for j, t2 in enumerate(tags):\n",
    "            if tag_counter[t1] > 0:  # if tag occurs at least once\n",
    "                transition_matrix[i][j] = transition_counter[(t1, t2)] / tag_counter[t1]  # compute transition probability\n",
    "\n",
    "    train_set.seek(0)\n",
    "    return transition_matrix\n",
    "\n",
    "\n",
    "def compute_emission_probabilities(train_set: Iterator[TokenList]) -> Dict[str, float]:\n",
    "    word_tag_counter = defaultdict(int)\n",
    "    tag_counter = defaultdict(int)\n",
    "    word_counter = defaultdict(int)\n",
    "\n",
    "    for sentence in parse_incr(train_set):\n",
    "        for token in sentence:                \n",
    "            word_tag_counter[(token['form'], token['lemma'])] += 1\n",
    "            tag_counter[token['lemma']] += 1\n",
    "\n",
    "    emission_probabilities = {(word, tag): count / tag_counter[tag] for (word, tag), count in word_tag_counter.items()}  # compute emission probability\n",
    "    train_set.seek(0)\n",
    "    return emission_probabilities\n",
    "\n",
    "\n",
    "def compute_emission_matrix(tags: List[str], words: List[str], emission_probabilities: [Dict[str, float]]) -> np.array:\n",
    "    emission_matrix = np.zeros((len(tags), len(words)), dtype=float)\n",
    "    for i, tag in enumerate(tags):\n",
    "        for j, word in enumerate(words):\n",
    "            emission_matrix[i, j] = emission_probabilities.get((word, tag), unknown_word_emission(smoothing_strategy, tag))\n",
    "\n",
    "    return emission_matrix\n",
    "\n",
    "\n",
    "def compute_one_shot_distrib(val_set: Iterator[TokenList]) -> Dict[str, float]:\n",
    "    word_tag_counter = defaultdict(int)\n",
    "    \n",
    "    for sentence in parse_incr(val_set):\n",
    "        for token in sentence:                \n",
    "            word_tag_counter[(token['form'], token['lemma'])] += 1\n",
    "    \n",
    "    one_shot_distrib = defaultdict(int)\n",
    "    if smoothing_strategy == SmoothingStrategy.one_shot_word:\n",
    "        for (word, tag), count in word_tag_counter.items():\n",
    "            if count == 1:\n",
    "                one_shot_distrib[tag] += 1\n",
    "        total_count = sum(one_shot_distrib.values())\n",
    "\n",
    "        for tag, count in one_shot_distrib.items():\n",
    "            one_shot_distrib[tag] = count / total_count\n",
    "    \n",
    "    return one_shot_distrib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7705c",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79396733",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_probabilities = compute_emission_probabilities(train_set)\n",
    "transition_matrix = np.log(compute_transition_matrix(tags, train_set) + laplace_correction)\n",
    "Π = transition_matrix[0, 1:]\n",
    "\n",
    "if smoothing_strategy == SmoothingStrategy.one_shot_word:\n",
    "    one_shot_distrib = compute_one_shot_distrib(val_set)\n",
    "\n",
    "tags.remove('START')\n",
    "transition_matrix = transition_matrix[1:, 1:]\n",
    "\n",
    "train_set.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transition_matrix, index=tags, columns=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abef94",
   "metadata": {},
   "source": [
    "## Definition of Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Need to use logarithm to compute argmax probability in order to improve performance\n",
    "def argmax(viterbi_matrix: np.array, Tm: np.array, j: int, i: int) -> Tuple[int, float]:\n",
    "    max_prob = np.NINF\n",
    "    max_index = 0\n",
    "    for index, prob in enumerate(viterbi_matrix[:, i-1]):\n",
    "        prob += Tm[index, j]\n",
    "        if prob > max_prob:\n",
    "            max_index, max_prob = index, prob\n",
    "    \n",
    "    return max_index, max_prob\n",
    "\n",
    "\n",
    "def viterbi(words: List[str], tags: List[str], Π: np.array, Tm: np.array, Em: np.array) -> List[str]:\n",
    "    W = len(words)\n",
    "    T = len(tags)\n",
    "\n",
    "    viterbi_matrix = np.full((T, W), np.NINF, dtype=float)\n",
    "    backpointer = np.empty((T, W), dtype=int)\n",
    "\n",
    "    # compute first word initial probability for each tag\n",
    "    viterbi_matrix[:, 0] = [emission + initial_p for emission, initial_p in zip(Em[:, 0], Π)]\n",
    "\n",
    "    # compute probabilities and fill backpointer for the rest of matrix\n",
    "    for i in range(1, W):\n",
    "        for j in range(T):\n",
    "            k, value = argmax(viterbi_matrix, Tm, j, i)\n",
    "            viterbi_matrix[j, i] = value + Em[j, i]\n",
    "            backpointer[j, i] = k\n",
    "\n",
    "    # get tag index k of last column with highest probability\n",
    "    last_column = list(viterbi_matrix[:, -1])\n",
    "    max_value = max(last_column)\n",
    "    k = last_column.index(max_value)\n",
    "\n",
    "    # get best path walking through backpointer\n",
    "    best_path = list()\n",
    "    for i in range(W-1, -1, -1):\n",
    "        best_path.append(tags[k])\n",
    "        k = backpointer[k, i]\n",
    "    \n",
    "    best_path.reverse()\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38094270",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "correctly_classified = 0\n",
    "for sentence in parse_incr(test_set):\n",
    "    total_words += len(sentence)\n",
    "    correct_tags = [token['lemma'] for token in sentence]\n",
    "    words = np.array([token['form'] for token in sentence])\n",
    "\n",
    "    emission_matrix = np.log(compute_emission_matrix(tags, words, emission_probabilities) + laplace_correction)\n",
    "    result_tags = viterbi(words, tags, Π, transition_matrix, emission_matrix)\n",
    "    \n",
    "    correctly_classified += sum(x == y for x, y in zip(correct_tags, result_tags))\n",
    "\n",
    "# TODO precision = tp / (tp + fp)\n",
    "# TODO recall = tp / (tp + fn)\n",
    "print(f'Total words: {total_words}')\n",
    "print(f'Correctly tagged: {correctly_classified}')\n",
    "print(f'Accuracy: {round(correctly_classified / total_words * 100, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
